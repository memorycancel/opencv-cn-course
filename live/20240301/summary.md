https://otter.ai/u/kcVDYxAlTCSoPjyYkheklQKuyl4?view=summary&tab=chat

OpenCV Live!

The conversation revolved around Apple's Vision Pro headset, with Speaker 1 introducing the device and highlighting its advanced camera technology. Speaker 2 provided insight into the engineering behind the headset, while Speaker 3 discussed the significance of the 12 cameras and two depth sensors for recognition. Speaker 4 shared their experience with the device's remarkable latency and tracking capabilities. The group also discussed the latest developments in VR technology, including the TrueDepth camera and Lidar sensor, and their applications in immersion and seamless interaction with virtual objects. Finally, Speaker 3 expressed hope for a more separated compute design to reduce weight on the headset.

Transcript

https://otter.ai/u/kcVDYxAlTCSoPjyYkheklQKuyl4?view=transcript

Action Items
[ ] Test Apple Vision Pro passthrough quality in different lighting conditions
[ ] Investigate which Apple Vision Pro cameras are used for 3D photo/video capture
[ ] Check if Apple Vision Pro camera sensors are optimized for low latency vs image quality
[ ] Write blog post about Apple Vision Pro hardware components
Outline
Apple's new Vision Pro headset and its coverage.
Speaker 1 mentions a write-up by Ed Zitron about the Apple Vision Pro headset, calling it "really good stuff."
Speaker 2 highlights the iFixit teardown videos as a standout in coverage, praising their engineering insights.
Mark Zuckerberg defends Meta Quest 3 investment, compares it to his own hairstyle evolution.
AI, OpenCV, and related technologies.
Bilawal Siddell is a creator, engineer, and product builder with experience at Google and as an independent entrepreneur.
Phil Nelson is the director of content and creative at Open CV, responsible for producing the show and hosting giveaways.
Speaker 1 introduces the Open CV five workboard, a public board showing what features are being worked on and completed, allowing users to plan accordingly.
Speaker 1 promotes the open CV merch shop, offering three shirt designs and stickers, with proceeds going to the nonprofit Open CV organization.
Speaker 1 introduces OpenCV's new support page, where donors can contribute via credit card or PayPal, and companies can join the membership organization plan with varying levels of financial support.
Speaker 2 mentions that OpenCV has gained new gold sponsors, including a chip manufacturer, and they are working with another company that may be announced soon.
AR/VR/spatial computing with industry expert.
Bulava do shares insights on AR/VR, spatial computing, and creative endeavors.
Computer vision and virtual video studio technology.
Speaker 3 shares experiences in spatial computing and computer vision, including building an app called Red Laser and working on the structure sensor with PrimeSense, which was later acquired by Apple.
White House Studios leverages computer vision and AI to create virtual game shows and studios.
Apple's Vision Probe with 12 cameras and 2 depth sensors.
Speaker 2 discusses the hardware of the Apple vision probe, highlighting its 12 cameras, lidar, true depth sensor, and IR cameras for hand tracking.
Speaker 2 also mentions the difference between the two main cameras and the downward-looking cameras, as well as the IR illuminators used for low-light scene recognition.
Speaker 2 highlights Apple's use of various biometric technologies, including facial recognition, iris detection, and touch ID, in their devices.
Speaker 3 discusses the dual cameras on the iPhone 12 Pro, including the true depth camera and Lidar scanner, and their potential uses for face mapping and 3D scanning.
Speaker 2 adds that the true depth camera is used for creating avatars and the 3D structure of the scene around the device, with applications that use a combination of Lidar and true depth sensors.
VR headset tracking and camera quality.
Speaker 4 praises the Quest Pro's camera system, particularly the downward and outward-facing cameras for comfort and tracking performance.
Speaker 4 and others agree that the Quest Pro's latency is impressively low, with one speaker calling it "phenomenal."
Speaker 3 expresses surprise at iPhone 15 camera quality, citing slow readout and exposure times.
Computer vision technology and device tracking.
Speaker 2 describes the experience of wearing Apple's Vision Probe, saying it's like looking at a video of the scene instead of the real thing (29 words)
Speaker 2 explains the tracking feature of the device, which allows users to see the whole room around them (28 words)
The device uses six cameras to track its position and rotation in the room, allowing it to project a window in the right perspective.
The tracking information is used to make the window feel like a physical object in the scene, not just a floating icon.
Apple's VR headset features and performance.
Speakers praise the hands-tracking technology in the new VR headset, finding it more immersive and realistic than previous devices.
Speaker 2 discusses the tracking technology in the new VR headset, mentioning the use of cameras and inertial motion sensors (IMU) to provide accurate tracking information.
Speaker 4 highlights the headset's ability to work well in different environments, such as airplanes and cars, despite the challenges of IMU data in those situations.
VR headset design and user experience.
Speaker 3 impressed by Meta Quest 2's low latency and accurate tracking, despite some fatigue in the neck area.
Speakers discuss the importance of neck exercises for using Apple's Vision Pro and iPhone for extended periods.